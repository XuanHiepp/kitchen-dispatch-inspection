{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **** Kitchen Dispatch Inspection Project, includes two steps: ****\n",
        "### 1. Train an object detection model to identify trays and dishes.\n",
        "### 2. Train a classification model to categorize the detected objects into three classes: \"not_empty\", \"empty\", and \"kakigori\".\n"
      ],
      "metadata": {
        "id": "ZZVAu4cSq2a8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install some required libraries"
      ],
      "metadata": {
        "id": "AmH-hz62o_-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ultralytics --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DETji9bTpEPB",
        "outputId": "73345b97-7ba8-4198-b4f0-c173db197f82"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Clone the project"
      ],
      "metadata": {
        "id": "zunoG0tktgJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b main https://github.com/XuanHiepp/kitchen-dispatch-inspection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akhtZCPPtfIy",
        "outputId": "c33909da-de90-4875-9295-babd01239b26"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'kitchen-dispatch-inspection'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 34 (delta 6), reused 24 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (34/34), 19.18 KiB | 19.18 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load dataset"
      ],
      "metadata": {
        "id": "nDbwiaifo5tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id \"1XyYw9ApGeSFkTl298yH4lYM6d_RwtHgg\"\n",
        "!unzip -q Dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvG7TEz7o8Wr",
        "outputId": "da94ae53-9520-42bd-8c7c-f6b1f87334d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1XyYw9ApGeSFkTl298yH4lYM6d_RwtHgg\n",
            "From (redirected): https://drive.google.com/uc?id=1XyYw9ApGeSFkTl298yH4lYM6d_RwtHgg&confirm=t&uuid=c4e9e965-8d57-49da-ae62-d200ad107f01\n",
            "To: /content/Dataset.zip\n",
            "100% 91.7M/91.7M [00:01<00:00, 70.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv Dataset kitchen-dispatch-inspection\n",
        "%cd kitchen-dispatch-inspection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8v5IXUJtpwn",
        "outputId": "e699767a-72d4-4c93-fe0b-f71b7057ddfd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/kitchen-dispatch-inspection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Setup model structure and training for detection task"
      ],
      "metadata": {
        "id": "AAOl_IDvpMcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Proprocess detection dataset"
      ],
      "metadata": {
        "id": "6ydkATIfqOxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    from modules.preprocess_image_det import YOLODatasetAugmentor\n",
        "\n",
        "    # New detection dataset saved at \"Dataset/Detection_augmented\" directory\n",
        "    augmentor = YOLODatasetAugmentor(\n",
        "        input_train_images='Dataset/Detection/train/images',\n",
        "        input_train_labels='Dataset/Detection/train/labels',\n",
        "        input_val_images='Dataset/Detection/val/images',\n",
        "        input_val_labels='Dataset/Detection/val/labels',\n",
        "        output_train_images='Dataset/Detection_augmented/train/images',\n",
        "        output_train_labels='Dataset/Detection_augmented/train/labels',\n",
        "        output_val_images='Dataset/Detection_augmented/val/images',\n",
        "        output_val_labels='Dataset/Detection_augmented/val/labels',\n",
        "        augmentations_per_image=5\n",
        "    )\n",
        "\n",
        "    augmentor.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dOHT1y6p62Q",
        "outputId": "101203bb-fe86-40c7-cb33-68a3db1188f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmentation completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Train the new detection dataset with yolov11"
      ],
      "metadata": {
        "id": "ZRlVSGZWqgZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download yolov11 model\n",
        "!gdown --id \"1nPpgjSd3nSh37-rORhkvJE1DfJZsgWu7\"\n",
        "!mv yolo11m.pt kitchen-dispatch-inspection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hikA9kq8uxqq",
        "outputId": "1a5f9b36-cf2b-4528-814b-092e389b3898"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1nPpgjSd3nSh37-rORhkvJE1DfJZsgWu7\n",
            "From (redirected): https://drive.google.com/uc?id=1nPpgjSd3nSh37-rORhkvJE1DfJZsgWu7&confirm=t&uuid=1262b89c-a97f-4a7f-bcf6-5a4478b4decc\n",
            "To: /content/kitchen-dispatch-inspection/yolo11m.pt\n",
            "100% 40.7M/40.7M [00:00<00:00, 141MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model will be saved in \"kitchen-dispatch-inspection/runs/detect/train/weights\"\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load pretrained YOLOv11 model\n",
        "model = YOLO('yolo11m.pt')\n",
        "\n",
        "# Start training\n",
        "results = model.train(\n",
        "    data='Dataset/Detection/dataset.yaml',\n",
        "    epochs=120,\n",
        "    imgsz=640,\n",
        "    batch=8,\n",
        "    device=0,\n",
        "    patience=10,\n",
        "    verbose=False,\n",
        "\n",
        "    # Augmentation for realtime images\n",
        "    degrees=5,\n",
        "    translate=0.02,\n",
        "    scale=0.3,\n",
        "    shear=0.3,\n",
        "    perspective=0.0001,\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    flipud=0.0,\n",
        "    fliplr=0.5,\n",
        "    mosaic=0.8,\n",
        "    mixup=0.0,\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer='auto',\n",
        "    cache=True,\n",
        "    warmup_epochs=3,\n",
        "    multi_scale=True\n",
        ")"
      ],
      "metadata": {
        "id": "WOs9xb6swIIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Setup model structure and training for classification task"
      ],
      "metadata": {
        "id": "FoYnvueTq_-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "model_save_dir = \"models\"\n",
        "os.makedirs(model_save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "tMU0EC5Pp686"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from modules.classifier import ClsModel\n",
        "from modules.preprocess_image_cls import ClsDataset\n",
        "\n",
        "def train_classifier(dataset, model_save_path, num_epochs=50, device='cuda'):\n",
        "    model = ClsModel(num_classes=len(dataset.classes)).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1)\n",
        "\n",
        "    best_val_acc = 0\n",
        "    early_stop_counter = 0\n",
        "    patience = 5\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, labels in dataset.train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in dataset.val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataset.train_loader):.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            save_dict = {\n",
        "                'model_state': model.state_dict(),\n",
        "                'classes': dataset.classes\n",
        "            }\n",
        "            torch.save(save_dict, model_save_path)\n",
        "            early_stop_counter = 0\n",
        "        else:\n",
        "            early_stop_counter += 1\n",
        "            if early_stop_counter >= patience:\n",
        "                print(\"Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "    print(\"Training complete. Best Val Acc:\", best_val_acc)"
      ],
      "metadata": {
        "id": "tQs3GAwZo9Ct"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation for the classification dataset with tray object\n",
        "tray_dataset = ClsDataset(dataset_path='Dataset/Classification/tray', batch_size=64)\n",
        "\n",
        "# Start training for tray object\n",
        "train_classifier(\n",
        "    tray_dataset,\n",
        "    model_save_path=model_save_dir + \"/cls_tray_best.pth\"\n",
        ")\n",
        "\n",
        "# Model will be saved in \"kitchen-dispatch-inspection/models/cls_tray_best.pth\""
      ],
      "metadata": {
        "id": "CzDM_OD0wwIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation for the classification dataset with dish object\n",
        "dish_dataset = ClsDataset(dataset_path='Dataset/Classification/dish', batch_size=64)\n",
        "\n",
        "# Start training for dish object\n",
        "train_classifier(\n",
        "    dish_dataset,\n",
        "    model_save_path=model_save_dir + \"/cls_dish_best.pth\"\n",
        ")\n",
        "\n",
        "# Model will be saved in \"kitchen-dispatch-inspection/models/cls_dish_best.pth\""
      ],
      "metadata": {
        "id": "WVpJaHErxDR1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}